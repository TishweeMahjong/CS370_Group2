{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TishweeMahjong/CS370_Group2/blob/Milestone2/CS370_FinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Milestone 1: Source Videos and Closed Captions"
      ],
      "metadata": {
        "id": "7THDsNSINWw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytube\n",
        "!pip install youtube_transcript_api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-7SJLOhLSw_",
        "outputId": "227a9e93-7478-4c44-8b40-c59f7c9ecce1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/57.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n",
            "Collecting youtube_transcript_api\n",
            "  Downloading youtube_transcript_api-0.6.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube_transcript_api) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (2023.7.22)\n",
            "Installing collected packages: youtube_transcript_api\n",
            "Successfully installed youtube_transcript_api-0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pytube import YouTube\n",
        "from pytube import Playlist\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n",
        "playlist_url = 'https://www.youtube.com/playlist?list=PLI1yx5Z0Lrv77D_g1tvF9u3FVqnrNbCRL'\n",
        "total_videos = 10\n",
        "\n",
        "# directory to store downloaded videos and captions\n",
        "video_directory = 'downloaded_videos'\n",
        "os.makedirs(video_directory, exist_ok=True)\n",
        "\n",
        "def download_video(video_url, video_directory):\n",
        "    try:\n",
        "        yt = YouTube(video_url)\n",
        "        video_stream = yt.streams.filter(progressive=True, file_extension='mp4').first()\n",
        "        video_stream.download(output_path=video_directory)\n",
        "        print(f\"Downloaded: {yt.title}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        return False\n",
        "\n",
        "def download_captions(video_id, video_directory):\n",
        "    try:\n",
        "        captions = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "        with open(os.path.join(video_directory, f\"{video_id}_captions.json\"), 'w', encoding='utf-8') as file:\n",
        "            file.write(str(captions))\n",
        "        print(f\"Downloaded captions for video ID: {video_id}\")\n",
        "    except Exception as e:\n",
        "        return False\n",
        "\n",
        "# Fetch videos from the playlist\n",
        "playlist = Playlist(playlist_url)\n",
        "\n",
        "# Download videos and captions\n",
        "downloaded_videos = 0\n",
        "\n",
        "for video_url in playlist.video_urls:\n",
        "    if downloaded_videos >= total_videos:\n",
        "        break\n",
        "\n",
        "    if download_video(video_url, video_directory):\n",
        "        video_id = video_url.split('v=')[1]\n",
        "        download_captions(video_id, video_directory)\n",
        "        downloaded_videos += 1\n",
        "\n",
        "print(f\"Downloaded {downloaded_videos} videos and their captions to {video_directory}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrDhw1vSO-tx",
        "outputId": "f6af2aaf-7ca1-4aef-cd57-d81d90e2b9bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded: Vice President Kamala Harris: The 2023 60 Minutes Interview\n",
            "Downloaded captions for video ID: G3Eup4mfJdA\n",
            "Downloaded: Pink: The 60 Minutes Interview\n",
            "Downloaded captions for video ID: 480OGItLZNo\n",
            "Downloaded: Rich Paul: The 60 Minutes Interview\n",
            "Downloaded captions for video ID: OA2Tj75T3fI\n",
            "Downloaded: \"Godfather of AI\" Geoffrey Hinton: The 60 Minutes Interview\n",
            "Downloaded captions for video ID: qrvK_KuIeJk\n",
            "Downloaded: Gen. Mark Milley: The 60 Minutes Interview\n",
            "Downloaded captions for video ID: oFVuQ0RP_As\n",
            "Downloaded: Attorney General Merrick Garland: The 60 Minutes Interview\n",
            "Downloaded captions for video ID: 4aPp8KX6EiU\n",
            "Downloaded: Deion Sanders: The 2023 60 Minutes Interview\n",
            "Downloaded captions for video ID: h8PSWeRLGXs\n",
            "Downloaded: Volodymyr Zelenskyy: The 2023 60 Minutes Interview\n",
            "Downloaded captions for video ID: Z8qC2tVkGeU\n",
            "Downloaded: Denzel Washington | 60 Minutes Archive\n",
            "Downloaded captions for video ID: Y9nM_9oBj2k\n",
            "Downloaded: World Number 1 Pool Player Shane Van Boening: The 60 Minutes Interview\n",
            "Downloaded captions for video ID: ervLwxz7xPo\n",
            "Downloaded 10 videos and their captions to downloaded_videos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Milestone 2: Speech to Text"
      ],
      "metadata": {
        "id": "idA2FgHni0Aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dependencies\n",
        "\n",
        "!pip install -q pytube\n",
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "\n",
        "import os, re\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from pytube import YouTube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcB882loi9XJ",
        "outputId": "530bdea2-3c94-4361-d71c-dd72bd083bfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.1/153.1 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "from whisper.utils import get_writer\n",
        "\n",
        "# Directory containing the downloaded video files\n",
        "video_directory = 'downloaded_videos'\n",
        "\n",
        "# Directory to store the transcribed text files\n",
        "transcription_directory = 'transcriptions'\n",
        "os.makedirs(transcription_directory, exist_ok=True)\n",
        "\n",
        "def transcribe_video(video_path, output_file):\n",
        "    try:\n",
        "        model = whisper.load_model(\"base\")\n",
        "        result = model.transcribe(video_path)\n",
        "        transcribed_text = result[\"text\"]\n",
        "\n",
        "        with open(output_file, 'w', encoding='utf-8') as text_file:\n",
        "            text_file.write(transcribed_text)\n",
        "\n",
        "        print(f\"Transcribed video: {video_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error transcribing video: {video_path}, Error: {str(e)}\")\n",
        "\n",
        "# Loop through the video files in the directory\n",
        "for filename in os.listdir(video_directory):\n",
        "    if filename.endswith(\".mp4\"):\n",
        "        video_path = os.path.join(video_directory, filename)\n",
        "        output_file = os.path.join(transcription_directory, f\"{os.path.splitext(filename)[0]}.txt\")\n",
        "        transcribe_video(video_path, output_file)\n",
        "\n",
        "print(f\"Transcriptions saved in {transcription_directory}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xM329t8K0OdZ",
        "outputId": "dfca4b20-ed63-47c9-8a32-471d354df067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 139M/139M [00:01<00:00, 122MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed video: downloaded_videos/World Number 1 Pool Player Shane Van Boening The 60 Minutes Interview.mp4\n",
            "Transcribed video: downloaded_videos/Pink The 60 Minutes Interview.mp4\n",
            "Transcribed video: downloaded_videos/Deion Sanders The 2023 60 Minutes Interview.mp4\n",
            "Transcribed video: downloaded_videos/Denzel Washington  60 Minutes Archive.mp4\n",
            "Transcribed video: downloaded_videos/Gen Mark Milley The 60 Minutes Interview.mp4\n",
            "Transcribed video: downloaded_videos/Vice President Kamala Harris The 2023 60 Minutes Interview.mp4\n",
            "Transcribed video: downloaded_videos/Rich Paul The 60 Minutes Interview.mp4\n",
            "Transcribed video: downloaded_videos/Volodymyr Zelenskyy The 2023 60 Minutes Interview.mp4\n",
            "Transcribed video: downloaded_videos/Attorney General Merrick Garland The 60 Minutes Interview.mp4\n",
            "Transcribed video: downloaded_videos/Godfather of AI Geoffrey Hinton The 60 Minutes Interview.mp4\n",
            "Transcriptions saved in transcriptions\n"
          ]
        }
      ]
    }
  ]
}